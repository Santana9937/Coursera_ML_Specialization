### Week 2 assignments for Coursera Machine Learning: Regression course from the University of Washington.

### Ipython notebook Multiple Regression with Sklearn

http://nbviewer.ipython.org/github/Santana9937/Regression_ML_Specialization/blob/master/Week_2_Multiple_Regression/assign-1_sklearn_mulp_regre.ipynb

In this notebook, we will use data on house sales in King County, Seatle to predict prices using multiple regression. The goal of this notebook is to explore multiple regression and feature engineering. You will:

* Use DataFrames to do some feature engineering
* Use sklearn to compute the regression weights (coefficients/parameters)
* Given the regression weights, predictors and outcome write a function to compute the Residual Sum of Squares (RSS)
* Look at coefficients and interpret their meanings
* Evaluate multiple models via RSS


### Ipython notebook for Gradient Descent Multiple Regression

http://nbviewer.ipython.org/github/Santana9937/Regression_ML_Specialization/blob/master/Week_2_Multiple_Regression/assign-2_grad_desc_mulp_regre.ipynb

In this notebook, we will cover estimating multiple regression weights via gradient descent. You will:
* Compute the derivative of the regression weights with respect to a single feature.
* Write a gradient descent function to compute the regression weights given an initial weight vector, step size, and tolerance.
* Use the gradient descent function to estimate regression weights for multiple features
* Write a predict_output() function. This function uses the weights obtained from gradient descent to predict the output for any feature we are interested in predicting (in this case, house price).


